<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Gitlab之邮箱配置]]></title>
    <url>%2Fpost%2Fdd7d75c9.html</url>
    <content type="text"><![CDATA[配置gitlab123456789101112vim /etc/gitlab/gitlab.rbgitlab_rails[&apos;smtp_enable&apos;] = truegitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.aliyun.com&quot;gitlab_rails[&apos;smtp_port&apos;] = 465gitlab_rails[&apos;smtp_user_name&apos;] = &quot;xxxx@aliyun.com&quot;gitlab_rails[&apos;smtp_password&apos;] = &quot;xxxxxxxx&quot;gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = truegitlab_rails[&apos;smtp_tls&apos;] = truegitlab_rails[&apos;gitlab_email_enabled&apos;] = truegitlab_rails[&apos;gitlab_email_from&apos;] = &apos;xxxx@aliyun.com&apos;gitlab_rails[&apos;gitlab_email_display_name&apos;] = &apos;Gitlab&apos;]]></content>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab 11 中文设置]]></title>
    <url>%2Fpost%2Ffc41e81.html</url>
    <content type="text"><![CDATA[手动下载zip包 https://gitlab.com/xhang/gitlab.git123cd /usr/local/src Wget https://gitlab.com/xhang/gitlab/-/archive/11-1-stable-zh/gitlab-11-1-stable-zh.tar.gzunzip gitlab-v11.1.0-zh.zip 解压之后查看版本123cat gitlab-v11.1.0-zh/VERSION11.1.0 跟英文版相比对，如果版本一样，进行下面 ##备份英文版 12 cp -r /opt/gitlab/embedded/service/gitlab-rails&#123;,.ori&#125; ##中文版覆盖英文版123456789cp -rf gitlab-v11.1.0-zh/* /opt/gitlab/embedded/service/gitlab-rails/重新配置gitlabgitlab-ctl reconfigure重启启动gitlabgitlab-ctl restart]]></content>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nexus搭建开发组的私有仓库]]></title>
    <url>%2Fpost%2Fe43e4e60.html</url>
    <content type="text"><![CDATA[一、私有仓库的价值 开发Java应用系统，用到Maven、sbt和 Gradle等构建工具，在构建过程中一般需要从互联网下载依赖库，构建私有仓库就是为了在开发组或者部门内共用，从而节省整体的下载成本和构建成本。下面先以Maven为例说明。 Maven是一个强大的构建工具，一般用于Java项目。Maven项目基于对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。Maven 除了以程序构建能力为特色之外，还提供高级项目管理工具。由于 Maven 的缺省构建规则有较高的可重用性，所以常常用两三行 Maven 构建脚本就可以构建简单的项目。 Maven的Java项目一般需要下载第三方组件，下载后构成本地仓库，为了减少网络对构建项目的影响，一般会构建私服仓库，代理第三方库。Nexus就是构建私服仓库的优秀软件。 二、准备工作2.1、安装Java编译环境Java编译环境包括核心的JDK和编译工具，因为Java的编译工具有很多种，而开源项目作者的随意性很高，常用的工具有maven，gradle,sbt，ant等等，本文关注Maven。 因为Oracle不再维护Java1.7，所以采用Java 1.8作为编译核心. 2.1.1、安装操作系统采用Centos7.4 yum install java-1.8.0-openjdk-devel java-1.8.0-openjdk java-1.8.0-openjdk-headless -y 2.1.2、验证查看jdk版本号 123456java -versionPicked up _JAVA_OPTIONS: -Xmx2048m -XX:MaxMetaspaceSize=512m -Djava.awt.headless=trueopenjdk version &quot;1.8.0_131&quot;OpenJDK Runtime Environment (build 1.8.0_131-b12)OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode) 三、安装Nexus3.1、下载nexus从官方网站现在最新3.X版 https://www.sonatype.com/download-oss-sonatype 下载（2018年3月）最新版nexus-3.9.0-01-unix.tar.gz （） 3.2、部署先规划存储私有仓库的目录，作者本机的/opt目录空间较多，所以以/opt为例12cd /opt/scmtar -xf ~/download/nexus-3.9.0-01-unix.tar.gz -C . 生成两个目录 nexus-3.9.0-01sonatype-work 3.3、系统服务1、编辑系统服务文件12345678910111213141516vi /etc/systemd/system/nexus.service[Unit]Description=nexus serviceAfter=network.target[Service]Type=forkingLimitNOFILE=65536ExecStart=/opt/scm/nexus-3.9.0-01/bin/nexus startExecStop=/opt/scm/nexus-3.9.0-01/bin/nexus stopUser=ansibleRestart=on-abort[Install]WantedBy=multi-user.target 2、设置为自启动服务1234sudo systemctl daemon-reloadsudo systemctl start nexus.servicesudo systemctl status nexus.servicesudo systemctl enable nexus.service 四、设置Nexus浏览器登录http://192.168.154.11:8081/ 用户名的密码为：admin admin123]]></content>
      <tags>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 libev.so.4()(64bit) is needed by percona-xtrabackup-2.3.4-1.el6.x86_64]]></title>
    <url>%2Fpost%2F2053e6f2.html</url>
    <content type="text"><![CDATA[到http://rpmfind.net/linux/rpm2html/search.php?query=libev.so.4%28%29%2864bit%29&amp;submit=Search+...&amp;system=&amp;arch= 下载操作系统对应的libev包，注意系统号与版本位数 1234wget ftp://rpmfind.net/linux/dag/redhat/el6/en/x86_64/dag/RPMS/libev-4.15-1.el6.rf.x86_64.rpmrpm -qa|grep libev (查找自带包)rpm -e libev**********（卸载自带包）rpm -ivh libev-4.15-1.el6.rf.x86_64.rpm]]></content>
      <tags>
        <tag>linux</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo链接持久化]]></title>
    <url>%2Fpost%2Ff5e46ae8.html</url>
    <content type="text"><![CDATA[1npm install hexo-abbrlink --save 站点配置文件里:1234permalink: post/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 另外可以修改scaffolds里的模版文件，修改post.md为:1234567---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;comments: truecategories:tags:--- 不建议的写法有的人采用了md文件的名字是英文，在Front-matter里将title写成正常的中文呢，这个将来文章多了，都是英文不利于收藏整理。]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch6.3.1 启用x-pack]]></title>
    <url>%2Fpost%2F89755df8.html</url>
    <content type="text"><![CDATA[**前言elasticsearch6.3.1安装包中已经集成了x-pack插件，无需使用elasticsearch-plugin install来安装x-pack，我们需要做的是使x-pack工作 步骤： 1、运行elasticsearch2、启用trial license（30天试用）1curl -H &quot;Content-Type:application/json&quot; -XPOST http://192.168.36.61:9200/_xpack/license/start_trial?acknowledge=true 可以看到elasticsearch控制台显示license 已变为trial 3、设置用户名密码1命令：bin/elasticsearch-setup-passwords interactive 修改密码方式：1curl -H &quot;Content-Type:application/json&quot; -XPOST -u elastic &apos;http://192.168.36.61:9200/_xpack/security/user/elastic/_password&apos; -d &apos;&#123; &quot;password&quot; : &quot;123456&quot; &#125;&apos; 4、elasticsearch.yml中开启安全验证配置此时访问http://192.168.36.61:9200 并不需要输入账号密码，需elasticsearch.yml中添加如下配置： xpack.security.enabled: true重启elasticsearch之后http://192.168.36.61:9200就需要使用账号验证了 head插件访问首先在elasticsearch.yml中添加配置： http.cors.enabled: true http.cors.allow-origin: “*” http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type访问head的时候带上用户名跟密码：http://192.168.36.61:9100/?auth_user=elastic&amp;auth_password=passwd]]></content>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum 安装mysql]]></title>
    <url>%2Fpost%2F88d36c2c.html</url>
    <content type="text"><![CDATA[在Red Hat Enterprise Linux和CentOS上安装Percona Server1.yum在线安装123yum install http://www.percona.com/downloads/percona-release/redhat/0.1-6/percona-release-0.1-6.noarch.rpmyum list | grep perconayum install Percona-Server-server-57 2.rpm包安装1234$ wget https://www.percona.com/downloads/Percona-Server-5.7/Percona-Server-5.7.10-3/binary/redhat/7/x86_64/Percona-Server-5.7.10-3-r63dafaf-el7-x86_64-bundle.tar$ tar xvf Percona-Server-5.7.10-3-r63dafaf-el7-x86_64-bundle.tar$ ls *.rpm$ rpm -ivh *.rpm]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7 安装最新版mariadb10.1]]></title>
    <url>%2Fpost%2Fd448c105.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[【MySQL报错】ERROR 1558 (HY000): Column count of mysql.user is wrong. Expected 43, found 39.]]></title>
    <url>%2Fpost%2F7068de52.html</url>
    <content type="text"><![CDATA[在网上查找原因说说因为升级不当导致，执行以下命令即可正常执行命令 mysql_upgrade -uroot -p]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上的 FirewallD 简明指南]]></title>
    <url>%2Fpost%2F28db6f30.html</url>
    <content type="text"><![CDATA[FirewallD 是 iptables 的前端控制器，用于实现持久的网络流量规则。它提供命令行和图形界面，在大多数 Linux 发行版的仓库中都有。与直接控制 iptables 相比，使用 FirewallD 有两个主要区别： 1.FirewallD 使用区域和服务而不是链式规则。 2.它动态管理规则集，允许更新规则而不破坏现有会话和连接。 FirewallD 是 iptables 的一个封装，可以让你更容易地管理 iptables 规则 - 它并不是 iptables 的替代品。虽然 iptables 命令仍可用于 FirewallD，但建议使用 FirewallD 时仅使用 FirewallD 命令。 本指南将向您介绍 FirewallD 的区域和服务的概念，以及一些基本的配置步骤。 安装与管理 FirewallD CentOS 7 和 Fedora 20+ 已经包含了 FirewallD，但是默认没有激活。可以像其它的 systemd 单元那样控制它。 1、 启动服务，并在系统引导时启动该服务：12systemctl start firewalldsystemctl enable firewalld 要停止并禁用：12systemctl start firewalldsystemctl enable firewalld 2、 检查防火墙状态。输出应该是 running 或者 not running。1firewall-cmd --state 3、 要查看 FirewallD 守护进程的状态：1systemctl status firewalld 4、 重新加载 FirewallD 配置：1firewall-cmd --reload 配置 FirewallD FirewallD 使用 XML 进行配置。除非是非常特殊的配置，你不必处理它们，而应该使用 firewall-cmd。 配置文件位于两个目录中： /usr/lib/FirewallD 下保存默认配置，如默认区域和公用服务。 避免修改它们，因为每次 firewall 软件包更新时都会覆盖这些文件。 /etc/firewalld 下保存系统配置文件。 这些文件将覆盖默认配置。 配置集 FirewallD 使用两个配置集：“运行时”和“持久”。 在系统重新启动或重新启动 FirewallD 时，不会保留运行时的配置更改，而对持久配置集的更改不会应用于正在运行的系统。 默认情况下，firewall-cmd 命令适用于运行时配置，但使用 –permanent 标志将保存到持久配置中。要添加和激活持久性规则，你可以使用两种方法之一。 1、 将规则同时添加到持久规则集和运行时规则集中。 12firewall-cmd --zone=public --add-service=http --permanentfirewall-cmd --zone=public --add-service=http 2、 将规则添加到持久规则集中并重新加载 FirewallD。 12firewall-cmd --zone=public --add-service=httpfirewall-cmd --reload reload 命令会删除所有运行时配置并应用永久配置。因为 firewalld 动态管理规则集，所以它不会破坏现有的连接和会话。 防火墙的区域 “区域”是针对给定位置或场景（例如家庭、公共、受信任等）可能具有的各种信任级别的预构建规则集。不同的区域允许不同的网络服务和入站流量类型，而拒绝其他任何流量。 首次启用 FirewallD 后，public 将是默认区域。 区域也可以用于不同的网络接口。例如，要分离内部网络和互联网的接口，你可以在 internal 区域上允许 DHCP，但在external 区域仅允许 HTTP 和 SSH。未明确设置为特定区域的任何接口将添加到默认区域。 要找到默认区域： 1firewall-cmd --get-default-zone 要修改默认区域：1firewall-cmd --set-default-zone=internal 要查看你网络接口使用的区域：1firewall --get-active-zones 要得到特定区域的所有配置：1firewall-cmd --zone=public --list-all 要得到所有区域的配置： 1firewall-cmd --list-all-zones 与服务一起使用 FirewallD 可以根据特定网络服务的预定义规则来允许相关流量。你可以创建自己的自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位于 /usr/lib /firewalld/services，用户创建的服务文件在 /etc/firewalld/services 中。 要查看默认的可用服务：1firewall-cmd --get-services 比如，要启用或禁用 HTTP 服务： 12firewall-cmd --zone=public --add-service=http --permanentfirewall-cmd --zone=public --remove-service=http --permanent 允许或者拒绝任意端口/协议12firewall-cmd --zone=public --add-port=12345/tcp --permanentfirewall-cmd --zone=public --remove-port=12345/tcp --permanent 端口转发 下面是在同一台服务器上将 80 端口的流量转发到 12345 端口。1firewalld-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toprt=12345 要将端口转发到另外一台服务器上： 1、 在需要的区域中激活 masquerade。1firewall-cmd --zone=public --add-masquerade 2、 添加转发规则。例子中是将本地的 80 端口的流量转发到 IP 地址为 ：123.456.78.9 的远程服务器上的 8080 端口。1firewall-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=123.456.78.9 要删除规则，用 –remove 替换 –add。比如：1firewall-cmd --zone=public --remove-masquerade 用 FirewallD 构建规则集 例如，以下是如何使用 FirewallD 为你的服务器配置基本规则（如果您正在运行 web 服务器）。 将 eth0 的默认区域设置为 dmz。 在所提供的默认区域中，dmz（非军事区）是最适合于这个程序的，因为它只允许 SSH 和 ICMP。12firewall-cmd --set-default-zone=dmzfirewall-cmd --zone=dmz --add-interface=eth0 2、 把 HTTP 和 HTTPS 添加永久的服务规则到 dmz 区域中：12firewall-cmd --zone=dmz --add-service=http --permanentfirewall-cmd --zone=dmz --add-service=https --permanent  3、 重新加载 FirewallD 让规则立即生效：1firewall-cmd --reload 高级配置 服务和端口适用于基本配置，但对于高级情景可能会限制较多。 丰富Rich规则和直接Direct接口允许你为任何端口、协议、地址和操作向任何区域 添加完全自定义的防火墙规则。 丰富规则 丰富规则的语法有很多，但都完整地记录在 firewalld.richlanguage(5) 的手册页中（或在终端中 man firewalld.richlanguage）。 使用 –add-rich-rule、–list-rich-rules 、 –remove-rich-rule 和 firewall-cmd 命令来管理它们。 这里有一些常见的例子： 允许来自主机 192.168.0.14 的所有 IPv4 流量。1firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot; ipv4 &quot; source address=192.168.0.14 accept&apos; 拒绝来自主机 192.168.1.10 到 22 端口的 IPv4 的 TCP 流量。1firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.10&quot; port port=22 protocol=tcp reject&apos; 允许来自主机 10.1.0.3 到 80 端口的 IPv4 的 TCP 流量，并将流量转发到 6532 端口上。 1firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.10&quot; forward-port port=80 protocol=tcp to-port=6532&apos; 将主机 172.31.4.2 上 80 端口的 IPv4 流量转发到 8080 端口（需要在区域上激活 masquerade）。1firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; forward-port port=80 protocol=tcp to-port=8080 to-addr=172.31.4.2&apos; 列出你目前的丰富规则：1firewall-cmd --list-rich-rules iptables 的直接接口 对于最高级的使用，或对于 iptables 专家，FirewallD 提供了一个直接Direct接口，允许你给它传递原始 iptables 命令。 直接接口规则不是持久的，除非使用 –permanent。 要查看添加到 FirewallD 的所有自定义链或规则：12firewall-cmd --direct --get-all-chainsfirewall-cmd --direct --get-all-rules]]></content>
      <tags>
        <tag>linux</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL binlog_format异常]]></title>
    <url>%2Fpost%2Fbb966997.html</url>
    <content type="text"><![CDATA[异常 执行jdbc查询时抛出异常： Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. 原因及解决方案 This is required by MySQL: Statement based binlogging does not work in isolation levelREAD UNCOMMITTED and READ COMMITTED since the necessarylocks cannot be taken. 根据tomcat抛异常，提示是事务级别在read committed和read uncommitted的时候binlog必须设置为row格式。 这个是java设置的一个局限性，java默认的事务级别是read committed，而mysql默认设置的binlog_format=statement。 将binlog_format设置为mixed set global binlog_format=mixed; 过段时间，异常仍在！ 设置成row set global binlog_format=row; 问题解决！ 或：1234mysql&gt; SET SESSION binlog_format = &apos;ROW&apos;;mysql&gt; SET GLOBAL binlog_format = &apos;ROW&apos;; 注意： 若手动修改linux下面/etc/my.cnf : binlog_format = row , 需要重启mysql。]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql主从关于函数过程同步问题]]></title>
    <url>%2Fpost%2Fc12bf416.html</url>
    <content type="text"><![CDATA[现mysql主从同上步 对于函数过程总是出错 MySQL创建函数问题分析： 根据系统提示，导致该错误的原因可能是一个安全设置方面的配置，查手册log_bin_trust_function_creators参数缺省0，是不 允许function的同步的。 一般我们在配置repliaction的时候，都忘记关注这个参数，这样在master更新funtion后，slave就会报告错误，然后slave stoped。 MySQL创建函数问题处理过程：登陆mysql数据库12&gt; set global log_bin_trust_function_creators ＝ 1;&gt; start slave; 跟踪mysql的启动日志，slave正常运行，问题解决。 持续跟踪，经过一个晚上，bin-relay-log的数据全部同步完毕。 直接在my.cnf里面添加1log_bin_trust_function_creators ＝ 1]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置location总结及rewrite规则写法]]></title>
    <url>%2Fpost%2F4b14c2dd.html</url>
    <content type="text"><![CDATA[1. location正则写法一个示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051location = / &#123; # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ]&#125;location / &#123; # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ]&#125;location /documents/ &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ]&#125;location ~ /documents/Abc &#123; # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ]&#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ]&#125;location /images/ &#123; # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ]&#125;location /images/abc &#123; # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ]&#125;location ~ /images/abc/ &#123; # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ]&#125;location ~* /js/.*/\.js 已=开头表示精确匹配如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。^~ 开头表示uri以某个常规字符串开头，不是正则匹配~ 开头表示区分大小写的正则匹配;~ 开头表示不区分大小写的正则匹配/ 通用匹配, 如果没有其它匹配,任何请求都会匹配到顺序 no优先级：(location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~,~ 正则顺序) &gt; (location 部分起始路径) &gt; (/) 上面的匹配结果按照上面的location写法，以下的匹配示例成立： / -&gt; config A精确完全匹配，即使/index.html也匹配不了/downloads/download.html -&gt; config B匹配B以后，往下没有任何匹配，采用B/images/1.gif -&gt; configuration D匹配到F，往下匹配到D，停止往下/images/abc/def -&gt; config D最长匹配到G，往下匹配D，停止往下你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序/documents/document.html -&gt; config C匹配到C，往下没有任何匹配，采用C/documents/1.jpg -&gt; configuration E匹配到C，往下正则匹配到E/documents/Abc.jpg -&gt; config CC最长匹配到C，往下正则顺序匹配到CC，不会往下到E123456789101112131415161718192021222324实际使用建议所以实际使用中，个人觉得至少有三个匹配规则定义，如下：#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。#这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125;# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;#第三个规则就是通用规则，用来转发动态请求到后端应用服务器#非静态文件请求就默认是动态请求，自己根据实际把握#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/&#125;http://tengine.taobao.org/book/chapter_02.htmlhttp://nginx.org/en/docs/http/ngx_http_rewrite_module.html 2. Rewrite规则rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag]; 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。 表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是： 执行server块的rewrite指令执行location匹配执行选定的location中的rewrite指令如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。 2.1 flag标志位last : 相当于Apache的[L]标记，表示完成rewritebreak : 停止执行当前虚拟主机的后续rewrite指令集redirect : 返回302临时重定向，地址栏会显示跳转后的地址permanent : 返回301永久重定向，地址栏会显示跳转后的地址因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： last一般写在server和if中，而break一般使用在location中last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配break和last都能组织继续执行后面的rewrite指令2.2 if指令与全局变量if判断指令语法为if(condition){…}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false直接比较变量和内容时，使用=或!=~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配-f和!-f用来判断是否存在文件-d和!-d用来判断是否存在目录-e和!-e用来判断是否存在文件或目录-x和!-x用来判断文件是否可执行 例如：12345678910111213141516171819202122232425262728293031if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; //如果UA包含&quot;MSIE&quot;，rewrite请求到/msid/目录下if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1; &#125; //如果cookie匹配正则，设置变量$id等于正则引用部分if ($request_method = POST) &#123; return 405;&#125; //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302if ($slow) &#123; limit_rate 10k;&#125; //限速，$slow可以通过 set 指令设置if (!-f $request_filename)&#123; break; proxy_pass http://127.0.0.1;&#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查if ($args ~ post=140)&#123; rewrite ^ http://example.com/ permanent;&#125; //如果query string中包含&quot;post=140&quot;，永久重定向到example.comlocation ~* \.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) &#123; return 404; &#125; //防盗链&#125; 全局变量下面是可以用作if判断的全局变量 $args ： #这个变量等于请求行中的参数，同$query_string$content_length ： 请求头中的Content-length字段。$content_type ： 请求头中的Content-Type字段。$document_root ： 当前请求在root指令中指定的值。$host ： 请求主机头字段，否则为服务器名称。$http_user_agent ： 客户端agent信息$http_cookie ： 客户端cookie信息$limit_rate ： 这个变量可以限制连接速率。$request_method ： 客户端请求的动作，通常为GET或POST。$remote_addr ： 客户端的IP地址。$remote_port ： 客户端的端口。$remote_user ： 已经经过Auth Basic Module验证的用户名。$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme ： HTTP方法（如http，https）。$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。$server_name ： 服务器名称。$server_port ： 请求到达服务器的端口号。$request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri ： 与$uri相同。例：http://localhost:88/test1/test2/test.php$host：localhost$server_port：88$request_uri：http://localhost:88/test1/test2/test.php$document_uri：/test1/test2/test.php$document_root：/var/www/html$request_filename：/var/www/html/test1/test2/test.php 2.3 常用正则. ： 匹配除换行符以外的任意字符? ： 重复0次或1次 ： 重复1次或更多次 ： 重复0次或更多次\d ：匹配数字^ ： 匹配字符串的开始$ ： 匹配字符串的介绍{n} ： 重复n次{n,} ： 重复n次或更多次[c] ： 匹配单个字符c[a-z] ： 匹配a-z小写字母的任意一个小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\转义特殊字符。 2.4 rewrite实例例1： http { # 定义image日志格式 log_format imagelog &apos;[$time_local] &apos; $image_file &apos; &apos; $image_type &apos; &apos; $body_bytes_sent &apos; &apos; $status; # 开启重写日志 rewrite_log on; server { root /home/www; location / { # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免{} rewrite &apos;^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\.(png|jpg|gif)$&apos; /data?file=$3.$4; # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行 set $image_file $3; set $image_type $4; } location /data { # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里 try_files /$arg_file /image404.html; } location = /image404.html { # 图片不存在返回特定的信息 return 404 &quot;image not found\n&quot;; } }对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。 例2： rewrite ^/images/(.*)_(\d+)x(\d+).(png|jpg|gif)$ /resizer/$1.$4?width=$2&amp;height=$3? last;对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql导出存储过程或函数]]></title>
    <url>%2Fpost%2F2afb17a8.html</url>
    <content type="text"><![CDATA[查询数据库中的存储过程和函数 方法一：select name from mysql.proc where db = ‘your_db_name’ and type = ‘PROCEDURE’ //存储过程select name from mysql.proc where db = ‘your_db_name’ and type = ‘FUNCTION’ //函数 方法二：show procedure status; //存储过程show function status; //函数 查看存储过程或函数的创建代码show create procedure proc_name;show create function func_name; mysql导出存储过程或函数： mysqldump -hhostname -uusername -ppassword -ntd -R databasename &gt; backupflie.sql 其中的 -ntd 是表示导出存储过程；-R是表示导出函数。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7使用pip安装mysqlclient提示mysql_config not found]]></title>
    <url>%2Fpost%2F551f39c7.html</url>
    <content type="text"><![CDATA[mysqlclient 是Python语言连接MariaDB / MySQL的链接库。Python程序可以使用mysqlclient连接到MariaDB / MySQL数据库，实现对MariaDB / MySQL数据库的操作。mysqlclient是MySQLdb1的一个分支，mysqlclient添加了对Python3的支持，并且修复了一些bug。 1、问题描述当我们使用pip安装mysqlclient时，提示mysql_config not found错误，具体信息如下： 12345678910111213141516(python-django) [anxin@bogon local]# pip install mysqlclientCollecting mysqlclient Downloading mysqlclient-1.3.12.tar.gz (89kB) 100% |████████████████████████████████| 92kB 16kB/s Complete output from command python setup.py egg_info: /bin/sh: mysql_config: 未找到命令 Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/tmp/pip-build-n0gegrlb/mysqlclient/setup.py&quot;, line 17, in &lt;module&gt; metadata, options = get_config() File &quot;/tmp/pip-build-n0gegrlb/mysqlclient/setup_posix.py&quot;, line 44, in get_config libs = mysql_config(&quot;libs_r&quot;) File &quot;/tmp/pip-build-n0gegrlb/mysqlclient/setup_posix.py&quot;, line 26, in mysql_config raise EnvironmentError(&quot;%s not found&quot; % (mysql_config.path,)) OSError: mysql_config not found ` 2、问题原因在你的系统上不存在mysql_config可执行文件，即：没有安装 mariadb 的链接库和头文件软件包。 3、解决方法：mysql_config是mariadb-devel或者mysql-devel包的一部分，mariadb-devel包是mariadb的链接库和头文件，不是mariadb的开发版本。链接库和头文件的版本需要和你安装的数据库版本相符。在使用链接库的情况下，不推荐使用SCL源安装MariaDB / MySQL。 3.1、安装链接库和头文件1）使用CentOS基本源安装的MariaDB / MySQL，使用如下命令安装MariaDB / MySQL链接库 1sudo yum install mariadb-devel #或者 mysql-devel在CentOS7中不存在1sudo yum install mysql-devel 2）使用CentOS IUS源安装的MariaDB / MySQL，安装MariaDB / MySQL对应版本的链接库包 1sudo yum install mariadb101u-devel #或者1sudo yum install mysql57u-devel 3）使用CentOS SCL源安装的MariaDB / MySQL，需要安装其他源（如：Base源，EPEL源，官方源，IUS源）中相应的链接库包（mariadb-devel）。]]></content>
      <tags>
        <tag>pip</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip安装升级]]></title>
    <url>%2Fpost%2Fda9bd2de.html</url>
    <content type="text"><![CDATA[使用get-pip.py进行安装要安装pip，请安全下载get-pip.py。[1]：1curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py 在运行从Web下载的任何脚本时，请确保您已查看过代码，并对它按预期工作而感到高兴。然后运行以下命令：1python get-pip.py 警告 如果您使用的是由操作系统或其他程序包管理器管理的Python安装，请务必小心。get-pip.py不与这些工具协调，可能会使系统处于不一致状态。get-pip.py如果还没有安装setuptools [2]和wheel也安装 它们。setuptools是安装源代码分发所必需的 。虽然两者都不需要安装预制轮子，但两者都是构建轮式缓存（提高安装速度）所必需的。 注意 与pip相同的python版本支持get-pip.py脚本。对于现在不支持Python 2.6中，替代脚本，请 点击这里。 升级PIP 在Linux或macOS上：1pip install -U pip 在Windows上[4]：1python -m pip install -U pip Python和OS兼容性pip适用于CPython版本2.7,3.4,3.5,3.6以及pypy。 这意味着pip适用于每个次要版本的最新补丁版本。尽力而为方法支持以前的修补程序版本。 pip适用于Unix / Linux，macOS和Windows。]]></content>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip设置阿里云的镜像源，速度超级快]]></title>
    <url>%2Fpost%2Fd08b91be.html</url>
    <content type="text"><![CDATA[linux下运行命令1vim ~/.pip/pip.conf 然后写入如下内容并保存123[global]trusted-host = mirrors.aliyun.comindex-url = https://mirrors.aliyun.com/pypi/simple windows:%HOMEPATH%\pip\pip.ini 内容同上]]></content>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7 mariaDb5.5 升级到最新版本]]></title>
    <url>%2Fpost%2F514081cc.html</url>
    <content type="text"><![CDATA[1.创建/etc/yum.repos.d/MariaDB.repo文件123456789cat &lt;&lt;EOF | sudo tee -a /etc/yum.repos.d/MariaDB.repo# MariaDB 10.1 CentOS repository list# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-10.1.25/yum/rhel7-amd64gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=0EOF 2.关闭并卸载旧版本的mariadb，安装新版本的mariadb。1234systemctl stop mariadbyum remove mariadb-server mariadb mariadb-libsyum clean allyum install MariaDB-server MariaDB-client 3.自定义数据目录和服务端口，移除默认的数据目录，创建新的数据目录。12rm -rf /var/lib/mysqlmkdir /var/data/db/mariadb 4.修改配置文件/etc/my.cnf.d/mysql-clients.cnf，重点是[client]，其他的可以参考12345678910111213141516171819[client]port = 3307socket = /var/data/db/mariadb/mysql.sock [mysql]no-auto-rehash [mysqldump]quickmax_allowed_packet = 64M [myisamchk]key_buffer_size = 128Msort_buffer_size = 128Mread_buffer = 2Mwrite_buffer = 2M [mysqlhotcopy]interactive-timeout 5.修改配置文件/etc/my.cnf.d/server.cnf，这里的性能参数来自my-large.ini文件123456789101112131415161718[mysqld]port = 3307datadir = /var/data/db/mariadbsocket = /var/data/db/mariadb/mysql.sockskip-external-lockingkey_buffer_size = 256Mmax_allowed_packet = 64Mtable_open_cache = 256sort_buffer_size = 1Mread_buffer_size = 1Mread_rnd_buffer_size = 4Mmyisam_sort_buffer_size = 64Mthread_cache_size = 8query_cache_size= 16Mthread_concurrency = 8log-bin=mysql-binbinlog_format=mixedserver-id = 1 6.初始化数据12mysql_install_db --defaults-file=/etc/my.cnf --datadir=/var/data/db/mariadb/ --user=mysql7.启动服务 systemctl restart mysql18.设置ROOT密码 mysqladmin -u root password “8888888”19.登陆mysql mysql -uroot -p1210.授权root远程登录root可从任何IP登陆，注意修改密码:&apos;888888&apos; mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘root‘@’%’ IDENTIFIED BY ‘888888’ WITH GRANT OPTION;mysql&gt;FLUSH RIVILEGES;1root可从指定IP登陆，注意修改密码:&apos;888888&apos;、IP:&apos;192.168.1.188&apos; mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘root‘@’192.168.1.188’ IDENTIFIED BY ‘888888’ WITH GRANT OPTION;mysql&gt;FLUSH RIVILEGES;`]]></content>
      <tags>
        <tag>mariadb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发情况下Linux系统及kernel参数优化]]></title>
    <url>%2Fpost%2Fe677ddc6.html</url>
    <content type="text"><![CDATA[众所周知在默认参数情况下Linux对高并发支持并不好，主要受限于单进程最大打开文件数限制、内核TCP参数方面和IO事件分配机制等。下面就从几方面来调整使Linux系统能够支持高并发环境。 Iptables相关 如非必须，关掉或卸载iptables防火墙，并阻止kernel加载iptables模块。这些模块会影响并发性能。 单进程最大打开文件数限制 一般的发行版，限制单进程最大可以打开1024个文件，这是远远不能满足高并发需求的，调整过程如下： 在#号提示符下敲入： ulimit–n 65535将root启动的单一进程的最大可以打开的文件数设置为65535个。如果系统回显类似于“Operationnotpermitted”之类的话，说明上述限制修改失败，实际上是因为在中指定的数值超过了Linux系统对该用户打开文件数的软限制或硬限制。因此，就需要修改Linux系统对用户的关于打开文件数的软限制和硬限制。 第一步，修改limits.conf文件，并添加： vim /etc/security/limits.conf softnofile 65536 hard nofile65536 其中’*’号表示修改所有用户的限制；soft或hard指定要修改软限制还是硬限制；65536则指定了想要修改的新的限制值，即最大打开文件数(请注意软限制值要小于或等于硬限制)。修改完后保存文件。 第二步，修改/etc/pam.d/login文件，在文件中添加如下行： vim /etc/pam.d/loginsessionrequired /lib/security/pam_limits.so 这是告诉Linux在用户完成系统登录后，应该调用pam_limits.so模块来设置系统对该用户可使用的各种资源数量的最大限制(包括用户可打开的最大文件数限制)，而pam_limits.so模块就会从/etc/security/limits.conf文件中读取配置来设置这些限制值。修改完后保存此文件。 第三步，查看Linux系统级的最大打开文件数限制，使用如下命令： cat/proc/sys/fs/file-max32568 这表明这台Linux系统最多允许同时打开(即包含所有用户打开文件数总和)32568个文件，是Linux系统级硬限制，所有用户级的打开文件数限制都不应超过这个数值。通常这个系统级硬限制是Linux系统在启动时根据系统硬件资源状况计算出来的最佳的最大同时打开文件数限制，如果没有特殊需要，不应该修改此限制，除非想为用户级打开文件数限制设置超过此限制的值。修改此硬限制的方法是修改/etc/sysctl.conf文件内fs.file-max= 131072 这是让Linux在启动完成后强行将系统级打开文件数硬限制设置为131072。修改完后保存此文件。 完成上述步骤后重启系统，一般情况下就可以将Linux系统对指定用户的单一进程允许同时打开的最大文件数限制设为指定的数值。如果重启后用ulimit-n命令查看用户可打开文件数限制仍然低于上述步骤中设置的最大值，这可能是因为在用户登录脚本/etc/profile中使用ulimit-n命令已经将用户可同时打开的文件数做了限制。由于通过ulimit-n修改系统对用户可同时打开文件的最大数限制时，新修改的值只能小于或等于上次ulimit-n设置的值，因此想用此命令增大这个限制值是不可能的。所以，如果有上述问题存在，就只能去打开/etc/profile脚本文件，在文件中查找是否使用了ulimit-n限制了用户可同时打开的最大文件数量，如果找到，则删除这行命令，或者将其设置的值改为合适的值，然后保存文件，用户退出并重新登录系统即可。 通过上述步骤，就为支持高并发TCP连接处理的通讯处理程序解除关于打开文件数量方面的系统限制。 内核TCP参数方面 Linux系统下，TCP连接断开后，会以TIME_WAIT状态保留一定的时间，然后才会释放端口。当并发请求过多的时候，就会产生大量的TIME_WAIT状态的连接，无法及时断开的话，会占用大量的端口资源和服务器资源。这个时候我们可以优化TCP的内核参数，来及时将TIME_WAIT状态的端口清理掉。 下面介绍的方法只对拥有大量TIME_WAIT状态的连接导致系统资源消耗有效，如果不是这种情况下，效果可能不明显。可以使用netstat命令去查TIME_WAIT状态的连接状态，输入下面的组合命令，查看当前TCP连接的状态和对应的连接数量： netstat-n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’这个命令会输出类似下面的结果： LAST_ACK16 SYN_RECV348 ESTABLISHED70 FIN_WAIT1229 FIN_WAIT230 CLOSING33 TIME_WAIT18098 我们只用关心TIME_WAIT的个数，在这里可以看到，有18000多个TIME_WAIT，这样就占用了18000多个端口。要知道端口的数量只有65535个，占用一个少一个，会严重的影响到后继的新连接。这种情况下，我们就有必要调整下Linux的TCP内核参数，让系统更快的释放TIME_WAIT连接。 编辑配置文件:/etc/sysctl.conf，在这个文件中，加入下面的几行内容： vim /etc/sysctl.confnet.ipv4.tcp_syncookies= 1 net.ipv4.tcp_tw_reuse= 1 net.ipv4.tcp_tw_recycle= 1 net.ipv4.tcp_fin_timeout= 30 输入下面的命令，让内核参数生效： sysctl-p简单的说明上面的参数的含义： net.ipv4.tcp_syncookies= 1 表示开启SYNCookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； net.ipv4.tcp_tw_reuse= 1 表示开启重用。允许将TIME-WAITsockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle= 1 表示开启TCP连接中TIME-WAITsockets的快速回收，默认为0，表示关闭； net.ipv4.tcp_fin_timeout 修改系統默认的TIMEOUT 时间。 在经过这样的调整之后，除了会进一步提升服务器的负载能力之外，还能够防御小流量程度的DoS、CC和SYN攻击。 此外，如果你的连接数本身就很多，我们可以再优化一下TCP的可使用端口范围，进一步提升服务器的并发能力。依然是往上面的参数文件中，加入下面这些配置： net.ipv4.tcp_keepalive_time= 1200 net.ipv4.ip_local_port_range= 1024 65535 net.ipv4.tcp_max_syn_backlog= 8192 net.ipv4.tcp_max_tw_buckets= 5000 这几个参数，建议只在流量非常大的服务器上开启，会有显著的效果。一般的流量小的服务器上，没有必要去设置这几个参数。 net.ipv4.tcp_keepalive_time= 1200 表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。 ip_local_port_range= 1024 65535 表示用于向外连接的端口范围。缺省情况下很小，改为1024到65535。 net.ipv4.tcp_max_syn_backlog= 8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 net.ipv4.tcp_max_tw_buckets= 5000 表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000。此项参数可以控制TIME_WAIT的最大数量，只要超出了。 内核其他TCP参数说明 net.ipv4.tcp_max_syn_backlog= 65536 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。 net.core.netdev_max_backlog= 32768 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 net.core.somaxconn= 32768 例如web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而nginx定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值。 net.core.wmem_default= 8388608 net.core.rmem_default= 8388608 net.core.rmem_max= 16777216 #最大socket读buffer,可参考的优化值:873200 net.core.wmem_max= 16777216 #最大socket写buffer,可参考的优化值:873200 net.ipv4.tcp_timestsmps= 0 时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 1 net.ipv4.tcp_synack_retries= 2 为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量。 net.ipv4.tcp_syn_retries= 2 在内核放弃建立连接之前发送SYN包的数量。 #net.ipv4.tcp_tw_len= 1 net.ipv4.tcp_tw_reuse= 1 开启重用。允许将TIME-WAITsockets重新用于新的TCP连接。 net.ipv4.tcp_wmem= 8192 436600 873200 TCP写buffer,可参考的优化值:8192 436600 873200 net.ipv4.tcp_rmem = 32768 436600 873200 TCP读buffer,可参考的优化值:32768 436600 873200 net.ipv4.tcp_mem= 94500000 91500000 92700000 同样有3个值,意思是: net.ipv4.tcp_mem[0]:低于此值，TCP没有内存压力。 net.ipv4.tcp_mem[1]:在此值下，进入内存压力阶段。 net.ipv4.tcp_mem[2]:高于此值，TCP拒绝分配socket。 上述内存单位是页，而不是字节。可参考的优化值是:7864321048576 1572864 net.ipv4.tcp_max_orphans= 3276800 系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。 如果超过这个数字，连接将即刻被复位并打印出警告信息。 这个限制仅仅是为了防止简单的DoS攻击，不能过分依靠它或者人为地减小这个值， 更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_fin_timeout= 30 如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60秒。2.2 内核的通常值是180秒，你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN-WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些。 同时还涉及到一个TCP 拥塞算法的问题，你可以用下面的命令查看本机提供的拥塞算法控制模块： sysctlnet.ipv4.tcp_available_congestion_control 对于几种算法的分析，详情可以参考下：TCP拥塞控制算法的优缺点、适用环境、性能分析，比如高延时可以试用hybla，中等延时可以试用htcp算法等。 如果想设置TCP 拥塞算法为hybla net.ipv4.tcp_congestion_control=hybla 额外的，对于内核版高于于3.7.1的，我们可以开启tcp_fastopen： net.ipv4.tcp_fastopen= 3 IO事件分配机制 在Linux启用高并发TCP连接，必须确认应用程序是否使用了合适的网络I/O技术和I/O事件分派机制。可用的I/O技术有同步I/O，非阻塞式同步I/O，以及异步I/O。在高TCP并发的情形下，如果使用同步I/O，这会严重阻塞程序的运转，除非为每个TCP连接的I/O创建一个线程。但是，过多的线程又会因系统对线程的调度造成巨大开销。因此，在高TCP并发的情形下使用同步I/O是不可取的，这时可以考虑使用非阻塞式同步I/O或异步I/O。非阻塞式同步I/O的技术包括使用select()，poll()，epoll等机制。异步I/O的技术就是使用AIO。 从I/O事件分派机制来看，使用select()是不合适的，因为它所支持的并发连接数有限(通常在1024个以内)。如果考虑性能，poll()也是不合适的，尽管它可以支持的较高的TCP并发数，但是由于其采用“轮询”机制，当并发数较高时，其运行效率相当低，并可能存在I/O事件分派不均，导致部分TCP连接上的I/O出现“饥饿”现象。而如果使用epoll或AIO，则没有上述问题(早期Linux内核的AIO技术实现是通过在内核中为每个I/O请求创建一个线程来实现的，这种实现机制在高并发TCP连接的情形下使用其实也有严重的性能问题。但在最新的Linux内核中，AIO的实现已经得到改进)。 综上所述，在开发支持高并发TCP连接的Linux应用程序时，应尽量使用epoll或AIO技术来实现并发的TCP连接上的I/O控制，这将为提升程序对高并发TCP连接的支持提供有效的I/O保证。 经过这样的优化配置之后，服务器的TCP并发处理能力会显著提高。以上配置仅供参考，用于生产环境请根据自己的实际情况调整观察再调整。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql定时任务简单例子]]></title>
    <url>%2Fpost%2F408d4340.html</url>
    <content type="text"><![CDATA[如果要每30秒执行以下语句：1update userinfo set endtime = now() WHERE id = &apos;110&apos;; 可以给mysql建个定时任务，具体方法如下：delimiter // / 设定语句终结符为 //，因存储过程语句用;结束 / 一、查看event是否开启123show variables like &apos;%sche%&apos;;开启event_schedulerset global event_scheduler =1; 二、创建存储过程test1234CREATE PROCEDURE test ()BEGINupdate userinfo set endtime = now() where id = &apos;110&apos;;END; 三、创建event e_test1234create event if not exists e_teston schedule every 30 secondon completion preservedo call test(); 每隔30秒将执行存储过程test 关闭事件任务1alter event e_test ON COMPLETION PRESERVE DISABLE; 开户事件任务1alter event e_test ON COMPLETION PRESERVE ENABLE;]]></content>
      <tags>
        <tag>mysq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Codis FE管理界面验证配置]]></title>
    <url>%2Fpost%2F7fc670d9.html</url>
    <content type="text"><![CDATA[安装所需的依赖包 1yum install -y gcc make gcc-c++ automake lrzsz openssl-devel zlib-* bzip2-* readline* zlib-* bzip2-* git 编译安装nginx123456789101112tar zxvf pcre-8.37.tar.gzcd pcre-8.37./configuremake &amp;&amp; make installtar zxvf nginx-1.8.0.tar.gzcd nginx-1.8.0#./configure --prefix=/usr/local/nginx./configure --prefix=/apps/svr/nginxmake &amp;&amp; make installcd /apps/svrchown -R apps:apps nginx 在线生成用户名和密码加密文件并写到指定文件中http://tool.oschina.net/htpasswd\将生成的结果复制到文件中。 12vim /apps/svr/nginx/conf/passcods_fe:$apr1$SSZq7WR.$QAPZd6dNYKtPtHigg7Yzm1 配置反向代理，启用验证功能 123456789101112131415161718192021222324252627282930313233vim /apps/svr/nginx/conf/nginx.confuser nobody;worker_processes 2;error_log logs/error.log notice;pid logs/nginx.pid;events &#123;worker_connections 1024;&#125;http &#123;include mime.types;default_type application/octet-stream;log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;&apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;#access_log logs/access.log main;sendfile on;#tcp_nopush on;keepalive_timeout 65;#gzip on;upstream dashboard &#123;server 192.168.24.103:8080;&#125;server &#123;listen 80;server_name 192.168.24.103;location / &#123;auth_basic &quot;Welcome to visit Codis dashboard.&quot;;auth_basic_user_file /apps/svr/nginx/conf;proxy_pass http://10.16.30.103:8080/;&#125;access_log logs/codis_dashboard.log main;&#125;&#125; 启动nginx 服务 1234567nginx停止nginxnginx -s stop重新加载nginx -s reload]]></content>
      <tags>
        <tag>codis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装、配置APR和tomcat-native]]></title>
    <url>%2Fpost%2F2ce30a80.html</url>
    <content type="text"><![CDATA[APR：Apache Portable Run-time libraries，Apache可移植执行库在早期的Apache版本号中。应用程序本身必须可以处理各种详细操作系统平台的细节，并针对不同的平台调用不同的处理函数。随着Apache的进一步开发。Apache组织决定将这些通用的函数独立出来并发展成为一个新的项目。这样。APR的开发就从Apache中独立出来，Apache不过使用APR而已。 Tomcat Native：这个项目能够让 Tomcat 使用 Apache 的 apr 包来处理包含文件和网络IO操作，以提升性能。官网介绍：The Apache Tomcat Native Library is an optional component for use with Apache Tomcat that allows Tomcat to use certain native resources for performance, compatibility, etc.（大概意思是Tomcat能够利用一些native资源来提高性能和兼容性。） Specifically, the Apache Tomcat Native Library gives Tomcat access to the Apache Portable Runtime (APR) library’s network connection (socket) implementation and random-number generator.（详细来说是利用了APR库中的网络连接实现和随机数生成器。） Features of the APR connector: Non-blocking I/O for Keep-Alive requests (between requests)Uses OpenSSL for TLS/SSL capabilities (if supported by linked APR library)FIPS 140-2 support for TLS/SSL (if supported by linked OpenSSL library) Linux下，Tomcat启用APR须要三个组件：aprapr-utiltomcat-native.tar.gz（Tomcat自带，在bin文件夹下） 1、查看是否已经安装了apr和apr-util12345# rpm -qa aprapr-1.4.8-3.el7.x86_64# rpm -qa apr-utilapr-util-1.5.2-6.el7.x86_64 2、查看是否有最新版的apr和apr-util123# yum list | grep aprapr.x86_64 1.4.8-3.el7 @anacondaapr-util.x86_64 1.5.2-6.el7 @anaconda 3、假设还没安装，用yum安装：1# yum install apr-devel apr apr-util 4、安装tomcat-native：搜索tomcat-native安装包：1# yum list | grep tomcat-native 假设已经存在，直接安装：123# yum install tomcat-native 正在安装 : tomcat-native-1.1.30-1.el7.x86_64 1/1 验证中 : tomcat-native-1.1.30-1.el7.x86_64 1/1 已安装: tomcat-native.x86_64 0:1.1.30-1.el7完成！ 查看是否成功安装：12# rpm -qa tomcat-nativetomcat-native-1.1.30-1.el7.x86_64 配置相关的全局变量：123# vi /etc/profile加入：export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/apr/lib# source /etc/profile 5、重新启动Tomcat。看看能否够成功使用APR假设一切正常：APR启动：[main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [“http-apr-18080”][main] org.apache.catalina.startup.Catalina.start Server startup in 13617 ms相比NIO模式的启动，速度快了一些（~15%）：NIO启动：[main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [“http-nio-18080”][main] org.apache.catalina.startup.Catalina.start Server startup in 15671 ms 假设发现异常log，比方：06-Aug-2015 14:46:04.949 SEVERE [main] org.apache.catalina.core.AprLifecycleListener.init An incompatible version 1.1.30 of the APR based Apache Tomcat Native library is installed, while Tomcat requires version 1.1.32 说明系统自带的tomcat-native版本号太低。删除：12345# yum erase tomcat-native用yum检查有没有最新版：# yum update tomcat-native假设yum找不到最新版。则下载或从Tomcat/bin中解压安装。 从Tomcat/bin文件夹中，解压tomcat-native.tar.gz文件：12345# tar -zxvf tomcat-native.tar.gz得到目录：tomcat-native-1.1.33-src# cd tomcat-native-1.1.33-src/jni/native/# ./configure --with-apr=/usr/local/apr （官网中样例的其它參数不须要，会自己主动找到）# make &amp;&amp; make install]]></content>
      <tags>
        <tag>tomcat</tag>
        <tag>linux优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAdvisor安装]]></title>
    <url>%2Fpost%2F3cfa0179.html</url>
    <content type="text"><![CDATA[SQLAdvisor安装1.1 拉取最新代码1git clone https://github.com/Meituan-Dianping/SQLAdvisor.git 1.2 安装依赖项121. yum | apt-get install cmake libaio-devel libffi-devel glib2 glib2-devel2. yum | apt-get install --enablerepo=Percona56 Percona-Server-shared-56 注意 跟据glib安装的路径，修改SQLAdvisor/sqladvisor/CMakeLists.txt中的两处include_directories针对glib设置的path。glib yum 安装默认不需要修改路径编译sqladvisor时依赖perconaserverclient_r, 因此需要安装Percona-Server-shared-56。有可能需要配置软链接例如:1. cd /usr/lib64/ 2. ln -s libperconaserverclient_r.so.18 libperconaserverclient_r.so有可能需要配置percona56 yum源: yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm1.3 编译依赖项sqlparser121. cmake -DBUILD_CONFIG=mysql_release -DCMAKE_BUILD_TYPE=debug -DCMAKE_INSTALL_PREFIX=/usr/local/sqlparser ./2. make &amp;&amp; make install 注意 DCMAKE_INSTALL_PREFIX为sqlparser库文件和头文件的安装目录，其中lib目录包含库文件libsqlparser.so，include目录包含所需的所有头文件。DCMAKE_INSTALL_PREFIX值尽量不要修改，后面安装依赖这个目录。1.4 安装SQLAdvisor源码1231. cd SQLAdvisor/sqladvisor/2. cmake -DCMAKE_BUILD_TYPE=debug ./3. make 在本路径下生成一个sqladvisor可执行文件，这即是我们想要的。 SQLAdvisor使用2.1 –help输出./sqladvisor –helpUsage:sqladvisor [OPTION…] sqladvisor SQL Advisor Summary Help Options: -?, –help Show help options Application Options: -f, –defaults-file sqls file -u, –username username -p, –password password -P, –port port -h, –host host -d, –dbname database name -q, –sqls sqls -v, –verbose 1:output logs 0:output nothing2.2 命令行传参调用./sqladvisor -h xx -P xx -u xx -p ‘xx’ -d xx -q “sql” -v 1 #####注意：命令行传参时，参数名与值需要用空格隔开 2.3 配置文件传参调用$&gt; cat sql.cnf[sqladvisor]username=xxpassword=xxhost=xxport=xxdbname=xxsqls=sql1;sql2;sql3…. cmd: ./sqladvisor -f sql.cnf -v 1]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos升级node]]></title>
    <url>%2Fpost%2F89c3f3c3.html</url>
    <content type="text"><![CDATA[安装方法: 1.产看node版本，没安装的请先安装；1$ node -v 2.清楚node缓存；1$ sudo npm cache clean -f 3.安装node版本管理工具’n’;1$ sudo npm install n -g 4.使用版本管理工具安装指定node或者升级到最新node版本；123$ sudo n stable （安装node最新版本）$ sudo n 8.9.4 （安装node指定版本8.9.4） 5.使用node -v查看node版本，如果版本号改变为你想要的则升级成功。 若版本号未改变则还需配置node环境变量1.查看通过n安装的node的位置；1$ which node (如：/usr/local/n/versions/node/6.12.3） 2.cd进入/usr/local/n/versions/node/ 你应该能看到你刚通过n安装的node版本这里如：8.9.4；编辑/etc/profile;1$ vim /etc/profile 3.将node安装的路径（这里为：/usr/local/n/versions/node/8.9.4）添加到文件末尾；12345#set node pathexport NODE_HOME=/usr/local/n/versions/node/8.9.4export PATH=$NODE_HOME/bin:$PATH 4.wq退出保存文件，编译/etc/profile;1$ source /etc/profile 5.再次使用node -v查看node版本，不出意外版本号应该变为你想要的。]]></content>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 使用及错误]]></title>
    <url>%2Fpost%2Ff7646ced.html</url>
    <content type="text"><![CDATA[1.保存修改的代码并更新方法1：如果你想保留刚才本地修改的代码，并把git服务器上的代码pull到本地（本地刚才修改的代码将会被暂时封存起来）123git stashgit pull origin mastergit stash pop 方法2、如果你想完全地覆盖本地的代码，只保留服务器端代码，则直接回退到上一个版本，再进行pull： 12git reset --hardgit pull origin master 2.fatal: unable to access ‘: Peer reports incompatible or unsupported protocol version\1yum update -y nss curl libcurl]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mariadb操作日志审计]]></title>
    <url>%2Fpost%2F30ecb4ef.html</url>
    <content type="text"><![CDATA[启用MariaDB的审计插件，并调整相关参数 12MariaDB [(none)]&gt; show variables like ‘%audit%‘;Empty set (0.02 sec) 安装MariaDB审计插件 12MariaDB [(none)]&gt; INSTALL PLUGIN server_audit SONAME ‘server_audit‘;Query OK, 0 rows affected (0.41 sec) 查看安装审计插件后的变量 [(none)]> show variables like ‘%audit%‘;12345678910111213141516171819+-------------------------------+-----------------------+| Variable_name | Value |+-------------------------------+-----------------------+| server_audit_events | || server_audit_excl_users | || server_audit_file_path | server_audit.log || server_audit_file_rotate_now | OFF || server_audit_file_rotate_size | 1000000 || server_audit_file_rotations | 9 || server_audit_incl_users | || server_audit_loc_info | || server_audit_logging | OFF || server_audit_mode | 0 || server_audit_output_type | file || server_audit_query_log_limit | 1024 || server_audit_syslog_facility | LOG_USER || server_audit_syslog_ident | mysql-server_auditing || server_audit_syslog_info | || server_audit_syslog_priority | LOG_INFO | 设置相关参数及说明： 1.设置记录的事件12MariaDB [(none)]&gt; set global server_audit_events=‘connect,query,table‘;Query OK, 0 rows affected (0.00 sec) 注：connect,query,table可满足我们所有审计需求 相关事件说明可参考：https://mariadb.com/kb/en/mariadb/about-the-mariadb-audit-plugin/ 2.指定不审计某些用户的操作12MariaDB [(none)]&gt; set global server_audit_excl_users=‘liuwei‘;Query OK, 0 rows affected (0.01 sec) 3.审计日志存放的位置 server_audit_file_path | server_audit.log4.设置日志轮转12MariaDB [(none)]&gt; set global server_audit_file_rotate_now=on;Query OK, 0 rows affected (0.00 sec) 5.设置审计日志的大小12MariaDB [(none)]&gt; set global server_audit_file_rotate_size=1024*1024*1024;Query OK, 0 rows affected (0.03 sec) 6.开启审计日志12MariaDB [(none)]&gt; set global server_audit_logging=on;Query OK, 0 rows affected (0.00 sec) 7.设置日志可以轮转的个数 server_audit_file_rotations | 9查看设置之后的参数：123456789101112131415161718192021MariaDB [(none)]&gt; show variables like ‘%audit%‘;+-------------------------------+-----------------------+| Variable_name | Value |+-------------------------------+-----------------------+| server_audit_events | QUERY,TABLE || server_audit_excl_users | liuwei || server_audit_file_path | server_audit.log || server_audit_file_rotate_now | OFF || server_audit_file_rotate_size | 1073741824 || server_audit_file_rotations | 9 || server_audit_incl_users | || server_audit_loc_info | || server_audit_logging | ON || server_audit_mode | 0 || server_audit_output_type | file || server_audit_query_log_limit | 1024 || server_audit_syslog_facility | LOG_USER || server_audit_syslog_ident | mysql-server_auditing || server_audit_syslog_info | || server_audit_syslog_priority | LOG_INFO |+-------------------------------+-----------------------+ 查看审计日志是否进行记录：可以记录增删改查所有操作123456789101112131415161718192021222324[root@test2 mysql]# cat server_audit.log 20160705 16:25:24,test2,root,localhost,9,2544,QUERY,,‘set global server_audit_logging=on‘,020160705 16:25:38,test2,root,localhost,9,2545,QUERY,,‘show variables like \‘%audit%\‘‘,020160705 16:28:06,test2,root,localhost,9,2546,QUERY,,‘SELECT DATABASE()‘,020160705 16:28:10,test2,root,localhost,9,2548,QUERY,,‘show databases‘,020160705 16:28:44,test2,root,localhost,9,2549,QUERY,,‘create database v1‘,0[root@test2 mysql]# tailf server_audit.log20160705 16:25:24,test2,root,localhost,9,2544,QUERY,,‘set global server_audit_logging=on‘,020160705 16:25:38,test2,root,localhost,9,2545,QUERY,,‘show variables like \‘%audit%\‘‘,020160705 16:28:06,test2,root,localhost,9,2546,QUERY,,‘SELECT DATABASE()‘,020160705 16:28:10,test2,root,localhost,9,2548,QUERY,,‘show databases‘,020160705 16:28:44,test2,root,localhost,9,2549,QUERY,,‘create database v1‘,020160705 16:31:20,test2,root,localhost,9,2552,QUERY,,‘set global server_audit_events=\‘connect,query,table\‘‘,020160705 16:31:30,test2,root,localhost,9,2553,QUERY,,‘show variables like \‘%audit%\‘‘,020160705 16:31:35,test2,root,localhost,9,0,DISCONNECT,,,020160705 16:31:51,test2,root,localhost,24,0,CONNECT,,,020160705 16:31:51,test2,root,localhost,24,2555,QUERY,,‘select @@version_comment limit 1‘,020160705 16:33:44,test2,root,192.168.10.215,25,0,FAILED_CONNECT,,,104520160705 16:33:44,test2,root,192.168.10.215,25,0,DISCONNECT,,,020160705 16:33:53,test2,liuwei,192.168.10.215,26,0,CONNECT,,,020160705 16:35:21,test2,root,localhost,24,2561,QUERY,,‘show variables like \‘%audit%\‘‘,020160705 16:40:22,test2,root,localhost,24,2563,WRITE,mysql,user,20160705 16:40:22,test2,root,localhost,24,2563,WRITE,mysql,db,20160705 16:40:22,test2,root,localhost,24,2563,QUERY,mysql,‘grant all on *.* to hb@\‘%\‘ identified by *****‘,0 在配置文件中配置审计参数，因为global重启后就失效： [mysqld] server_audit_events=‘CONNECT,QUERY,TABLE‘ server_audit_logging=on server_audit_file_rotate_size=200000 server_audit_file_rotations=10 server_audit_excl_users=‘liuwei‘ 重启生效]]></content>
      <tags>
        <tag>mariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7.4 安装 Inception]]></title>
    <url>%2Fpost%2Faea77668.html</url>
    <content type="text"><![CDATA[Cetos7.4系统 环境设置 12345678910111213141516171819202122232425yum install cmake ncurses-devel gcc gcc-c++ openssl-develyum remove bison -ycd /usr/local/src/wget http://ftp.gnu.org/gnu/m4/m4-1.4.18.tar.gztar -zxvf m4-1.4.18.tar.gzcd m4-1.4.18./configure &amp;&amp; make &amp;&amp; make installwget http://ftp.gnu.org/gnu/bison/bison-2.4.tar.gztar -zxvf bison-2.4.tar.gzcd bison-2.4/./configurecd /usr/local/wget https://github.com/mysql-inception/inception/archive/master.zipunzip master.zipmv inception-master/ inceptionmv master.zip inception.zipmv inception.zip /usr/local/src/sh inception_build.sh builddir linux 123456789101112131415161718192021vim inc.cnf[inception]general_log=1general_log_file=inception.logport=6669socket=/tmp/mysql.sockcharacter-set-client-handshake=0character-set-server=utf8inception_remote_system_password=rootinception_remote_system_user=123456inception_remote_backup_port=3306inception_remote_backup_host=127.0.0.1inception_support_charset=utf8mb4inception_enable_nullable=0inception_check_primary_key=1inception_check_column_comment=1inception_check_table_comment=1inception_osc_min_table_size=1inception_osc_bin_dir=/data/tempinception_osc_chunk_time=0.1inception_enable_blob_type=1 启动测试12nohup /usr/local/inception/builddir/mysql/bin/Inception --defaults-file=inc.cnf &gt;/dev/null 2&gt;&amp;1 &amp; 1234mysql -uroot -h127.0.0.1 -P6669inception get variables;inception_check_column_default_value=1]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux CentOS7 安装 RabbitMQ 3.6.3, Erlang 19.0]]></title>
    <url>%2Fpost%2F9ded5e27.html</url>
    <content type="text"><![CDATA[安装erlang 安装依赖环境1yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel unixODBC-devel 下载最新 Erlang 19.01wget http://erlang.org/download/otp_src_19.0.tar.gz 解压1tar -xvzf otp_src_19.0.tar.gz 配置12345./configure --prefix=/usr/local/erlang --with-ssl -enable-threads -enable-smmp-support -enable-kernel-poll --enable-hipe --without-javacmakemake install 配置profile ERLANG_HOME=/usr/local/erlangPATH=$PATH:$JAVA_HOME/bin:$ERLANG_HOME/bin 使其生效 123source /etc/profile echo $PATH 检验erl12345[root@iZ25sabz8p5Z sbin]# erlErlang/OTP 19 [erts-8.0] [source] [64-bit] [async-threads:10] [hipe] [kernel-poll:false]Eshell V8.0 (abort with ^G) 安装 rabbitmq123456789wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.3/rabbitmq-server-generic-unix-3.6.3.tar.xzxz -d rabbitmq-server-generic-unix-3.6.3.tar.xztar -xvf rabbitmq-server-generic-unix-3.6.3.tarcd ./rabbitmq_server-3.6.3cd sbin/ 启动1./rabbitmq-server -detached 添加用户1./rabbitmqctl add_user admin 111111 设置权限1./rabbitmqctl set_user_tags admin administrator 浏览器访问 ip:15672启用web管理界面1./rabbitmq-plugins enable rabbitmq_management]]></content>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
</search>
